{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtuOtZ6qFbD5txMXlXyeP8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sftSalman/Image_segmentation/blob/main/Car_image_segmention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MrbqU8Yawsuz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input,Conv2D,MaxPool2D,Dropout,Conv2DTranspose,concatenate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is utilities function \n",
        "import numpy as np\n",
        "from termcolor import colored\n",
        "\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout \n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "# Compare the two inputs\n",
        "def comparator(learner, instructor):\n",
        "    for a, b in zip(learner, instructor):\n",
        "        if tuple(a) != tuple(b):\n",
        "            print(colored(\"Test failed\", attrs=['bold']),\n",
        "                  \"\\n Expected value \\n\\n\", colored(f\"{b}\", \"green\"), \n",
        "                  \"\\n\\n does not match the input value: \\n\\n\", \n",
        "                  colored(f\"{a}\", \"red\"))\n",
        "            raise AssertionError(\"Error in test\") \n",
        "    print(colored(\"All tests passed!\", \"green\"))\n",
        "\n",
        "# extracts the description of a given model\n",
        "def summary(model):\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    result = []\n",
        "    for layer in model.layers:\n",
        "        descriptors = [layer.__class__.__name__, layer.output_shape, layer.count_params()]\n",
        "        if (type(layer) == Conv2D):\n",
        "            descriptors.append(layer.padding)\n",
        "            descriptors.append(layer.activation.__name__)\n",
        "            descriptors.append(layer.kernel_initializer.__class__.__name__)\n",
        "        if (type(layer) == MaxPooling2D):\n",
        "            descriptors.append(layer.pool_size)\n",
        "        if (type(layer) == Dropout):\n",
        "            descriptors.append(layer.rate)\n",
        "        result.append(descriptors)\n",
        "    return result\n",
        "\n",
        "def datatype_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += datatype_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(\"Error: {} in variable {}. Got {} but expected type {}\".format(error,\n",
        "                                                                          key, type(target_output[key]), type(expected_output[key])))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += datatype_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} in variable {}, expected type: {}  but expected type {}\".format(error,\n",
        "                                                                          i, type(target_output[i]), type(expected_output[i])))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        assert isinstance(target_output, type(expected_output))\n",
        "        return 1\n",
        "            \n",
        "def equation_output_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += equation_output_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable {}.\".format(error,\n",
        "                                                                          key))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += equation_output_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable in position {}.\".format(error, i))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        if hasattr(target_output, 'shape'):\n",
        "            np.testing.assert_array_almost_equal(target_output, expected_output)\n",
        "        else:\n",
        "            assert target_output == expected_output\n",
        "        return 1\n",
        "    \n",
        "def shape_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += shape_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable {}.\".format(error, key))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += shape_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable {}.\".format(error, i))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        if hasattr(target_output, 'shape'):\n",
        "            assert target_output.shape == expected_output.shape\n",
        "        return 1\n",
        "                \n",
        "def single_test(test_cases, target):\n",
        "    success = 0\n",
        "    for test_case in test_cases:\n",
        "        try:\n",
        "            if test_case['name'] == \"datatype_check\":\n",
        "                assert isinstance(target(*test_case['input']),\n",
        "                                  type(test_case[\"expected\"]))\n",
        "                success += 1\n",
        "            if test_case['name'] == \"equation_output_check\":\n",
        "                assert np.allclose(test_case[\"expected\"],\n",
        "                                   target(*test_case['input']))\n",
        "                success += 1\n",
        "            if test_case['name'] == \"shape_check\":\n",
        "                assert test_case['expected'].shape == target(*test_case['input']).shape\n",
        "                success += 1\n",
        "        except:\n",
        "            print(\"Error: \" + test_case['error'])\n",
        "            \n",
        "    if success == len(test_cases):\n",
        "        print(\"\\033[92m All tests passed.\")\n",
        "    else:\n",
        "        print('\\033[92m', success,\" Tests passed\")\n",
        "        print('\\033[91m', len(test_cases) - success, \" Tests failed\")\n",
        "        raise AssertionError(\"Not all tests were passed for {}. Check your equations and avoid using global variables inside the function.\".format(target.__name__))\n",
        "        \n",
        "def multiple_test(test_cases, target):\n",
        "    success = 0\n",
        "    for test_case in test_cases:\n",
        "        try:\n",
        "            target_answer = target(*test_case['input'])                   \n",
        "            if test_case['name'] == \"datatype_check\":\n",
        "                success += datatype_check(test_case['expected'], target_answer, test_case['error'])\n",
        "            if test_case['name'] == \"equation_output_check\":\n",
        "                success += equation_output_check(test_case['expected'], target_answer, test_case['error'])\n",
        "            if test_case['name'] == \"shape_check\":\n",
        "                success += shape_check(test_case['expected'], target_answer, test_case['error'])\n",
        "        except:\n",
        "            print(\"Error: \" + test_case['error'])\n",
        "            \n",
        "    if success == len(test_cases):\n",
        "        print(\"\\033[92m All tests passed.\")\n",
        "    else:\n",
        "        print('\\033[92m', success,\" Tests passed\")\n",
        "        print('\\033[91m', len(test_cases) - success, \" Tests failed\")\n",
        "        raise AssertionError(\"Not all tests were passed for {}. Check your equations and avoid using global variables inside the function.\".format(target.__name__))\n",
        "        \n",
        "        "
      ],
      "metadata": {
        "id": "8AT-OEPxyQow"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model_output = [['InputLayer', [(None, 96, 128, 3)], 0],\n",
        "['Conv2D', (None, 96, 128, 32), 896, 'same', 'relu', 'HeNormal'],\n",
        "['Conv2D', (None, 96, 128, 32), 9248, 'same', 'relu', 'HeNormal'],\n",
        "['MaxPooling2D', (None, 48, 64, 32), 0, (2, 2)],\n",
        "['Conv2D', (None, 48, 64, 64), 18496, 'same', 'relu', 'HeNormal'],\n",
        "['Conv2D', (None, 48, 64, 64), 36928, 'same', 'relu', 'HeNormal'],\n",
        "['MaxPooling2D', (None, 24, 32, 64), 0, (2, 2)],\n",
        "['Conv2D', (None, 24, 32, 128), 73856, 'same', 'relu', 'HeNormal'],\n",
        "['Conv2D', (None, 24, 32, 128), 147584, 'same', 'relu', 'HeNormal'],\n",
        "['MaxPooling2D', (None, 12, 16, 128), 0, (2, 2)],\n",
        "['Conv2D', (None, 12, 16, 256), 295168, 'same', 'relu', 'HeNormal'],\n",
        "['Conv2D', (None, 12, 16, 256), 590080, 'same', 'relu', 'HeNormal'],\n",
        "['Dropout', (None, 12, 16, 256), 0, 0.3],\n",
        "['MaxPooling2D', (None, 6, 8, 256), 0, (2, 2)],\n",
        "['Conv2D', (None, 6, 8, 512), 1180160, 'same', 'relu', 'HeNormal'],\n",
        "['Conv2D', (None, 6, 8, 512), 2359808, 'same', 'relu', 'HeNormal'],\n",
        "['Dropout', (None, 6, 8, 512), 0, 0.3],\n",
        "['Conv2DTranspose', (None, 12, 16, 256), 1179904],\n",
        "['Concatenate', (None, 12, 16, 512), 0],\n",
        "['Conv2D', (None, 12, 16, 256), 1179904, 'same', 'relu', 'HeNormal'],\n",
        "['Conv2D', (None, 12, 16, 256), 590080, 'same', 'relu', 'HeNormal'],\n",
        "['Conv2DTranspose', (None, 24, 32, 128), 295040],\n",
        "['Concatenate', (None, 24, 32, 256), 0],\n",
        "['Conv2D', (None, 24, 32, 128), 295040, 'same', 'relu', 'HeNormal'],\n",
        "['Conv2D', (None, 24, 32, 128), 147584, 'same', 'relu', 'HeNormal'],\n",
        "['Conv2DTranspose', (None, 48, 64, 64), 73792],\n",
        "['Concatenate', (None, 48, 64, 128), 0],\n",
        "['Conv2D', (None, 48, 64, 64), 73792, 'same', 'relu', 'HeNormal'],\n",
        "['Conv2D', (None, 48, 64, 64), 36928, 'same', 'relu', 'HeNormal'],\n",
        "['Conv2DTranspose', (None, 96, 128, 32), 18464],\n",
        "['Concatenate', (None, 96, 128, 64), 0],\n",
        "['Conv2D', (None, 96, 128, 32), 18464, 'same', 'relu', 'HeNormal'],\n",
        "['Conv2D', (None, 96, 128, 32), 9248, 'same', 'relu', 'HeNormal'],\n",
        "['Conv2D', (None, 96, 128, 32), 9248, 'same', 'relu', 'HeNormal'],\n",
        "['Conv2D', (None, 96, 128, 23), 759, 'same', 'linear', 'GlorotUniform']]"
      ],
      "metadata": {
        "id": "kTh3v6Dd1t1_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from termcolor import colored\n",
        "\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout \n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "# Compare the two inputs\n",
        "def comparator(learner, instructor):\n",
        "    for a, b in zip(learner, instructor):\n",
        "        if tuple(a) != tuple(b):\n",
        "            print(colored(\"Test failed\", attrs=['bold']),\n",
        "                  \"\\n Expected value \\n\\n\", colored(f\"{b}\", \"green\"), \n",
        "                  \"\\n\\n does not match the input value: \\n\\n\", \n",
        "                  colored(f\"{a}\", \"red\"))\n",
        "            raise AssertionError(\"Error in test\") \n",
        "    print(colored(\"All tests passed!\", \"green\"))\n",
        "\n",
        "# extracts the description of a given model\n",
        "def summary(model):\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    result = []\n",
        "    for layer in model.layers:\n",
        "        descriptors = [layer.__class__.__name__, layer.output_shape, layer.count_params()]\n",
        "        if (type(layer) == Conv2D):\n",
        "            descriptors.append(layer.padding)\n",
        "            descriptors.append(layer.activation.__name__)\n",
        "            descriptors.append(layer.kernel_initializer.__class__.__name__)\n",
        "        if (type(layer) == MaxPooling2D):\n",
        "            descriptors.append(layer.pool_size)\n",
        "        if (type(layer) == Dropout):\n",
        "            descriptors.append(layer.rate)\n",
        "        result.append(descriptors)\n",
        "    return result\n",
        "\n",
        "def datatype_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += datatype_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(\"Error: {} in variable {}. Got {} but expected type {}\".format(error,\n",
        "                                                                          key, type(target_output[key]), type(expected_output[key])))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += datatype_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} in variable {}, expected type: {}  but expected type {}\".format(error,\n",
        "                                                                          i, type(target_output[i]), type(expected_output[i])))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        assert isinstance(target_output, type(expected_output))\n",
        "        return 1\n",
        "            \n",
        "def equation_output_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += equation_output_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable {}.\".format(error,\n",
        "                                                                          key))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += equation_output_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable in position {}.\".format(error, i))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        if hasattr(target_output, 'shape'):\n",
        "            np.testing.assert_array_almost_equal(target_output, expected_output)\n",
        "        else:\n",
        "            assert target_output == expected_output\n",
        "        return 1\n",
        "    \n",
        "def shape_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += shape_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable {}.\".format(error, key))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += shape_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable {}.\".format(error, i))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        if hasattr(target_output, 'shape'):\n",
        "            assert target_output.shape == expected_output.shape\n",
        "        return 1\n",
        "                \n",
        "def single_test(test_cases, target):\n",
        "    success = 0\n",
        "    for test_case in test_cases:\n",
        "        try:\n",
        "            if test_case['name'] == \"datatype_check\":\n",
        "                assert isinstance(target(*test_case['input']),\n",
        "                                  type(test_case[\"expected\"]))\n",
        "                success += 1\n",
        "            if test_case['name'] == \"equation_output_check\":\n",
        "                assert np.allclose(test_case[\"expected\"],\n",
        "                                   target(*test_case['input']))\n",
        "                success += 1\n",
        "            if test_case['name'] == \"shape_check\":\n",
        "                assert test_case['expected'].shape == target(*test_case['input']).shape\n",
        "                success += 1\n",
        "        except:\n",
        "            print(\"Error: \" + test_case['error'])\n",
        "            \n",
        "    if success == len(test_cases):\n",
        "        print(\"\\033[92m All tests passed.\")\n",
        "    else:\n",
        "        print('\\033[92m', success,\" Tests passed\")\n",
        "        print('\\033[91m', len(test_cases) - success, \" Tests failed\")\n",
        "        raise AssertionError(\"Not all tests were passed for {}. Check your equations and avoid using global variables inside the function.\".format(target.__name__))\n",
        "        \n",
        "def multiple_test(test_cases, target):\n",
        "    success = 0\n",
        "    for test_case in test_cases:\n",
        "        try:\n",
        "            target_answer = target(*test_case['input'])                   \n",
        "            if test_case['name'] == \"datatype_check\":\n",
        "                success += datatype_check(test_case['expected'], target_answer, test_case['error'])\n",
        "            if test_case['name'] == \"equation_output_check\":\n",
        "                success += equation_output_check(test_case['expected'], target_answer, test_case['error'])\n",
        "            if test_case['name'] == \"shape_check\":\n",
        "                success += shape_check(test_case['expected'], target_answer, test_case['error'])\n",
        "        except:\n",
        "            print(\"Error: \" + test_case['error'])\n",
        "            \n",
        "    if success == len(test_cases):\n",
        "        print(\"\\033[92m All tests passed.\")\n",
        "    else:\n",
        "        print('\\033[92m', success,\" Tests passed\")\n",
        "        print('\\033[91m', len(test_cases) - success, \" Tests failed\")\n",
        "        raise AssertionError(\"Not all tests were passed for {}. Check your equations and avoid using global variables inside the function.\".format(target.__name__))\n",
        "        \n",
        "        \n",
        "        \n"
      ],
      "metadata": {
        "id": "Fl94vrWU2XDb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data and Data Preprosessing "
      ],
      "metadata": {
        "id": "orW5ehM2ybjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import pandas as pd \n",
        "import imageio \n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "QD3wB1gSy5X7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder=\"/kaggle/input/cityscapes-image-pairs/cityscapes_data/cityscapes_data/train\"\n",
        "valid_folder=\"/kaggle/input/cityscapes-image-pairs/cityscapes_data/cityscapes_data/val\"\n",
        "width = 256\n",
        "height = 256\n",
        "classes = 13\n",
        "batch_size = 10\n",
        "num_of_training_samples = len(os.listdir(train_folder)) \n",
        "num_of_testing_samples = len(os.listdir(valid_folder))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "GN420n1uzHaB",
        "outputId": "8115e8df-68b0-4bac-a0e5-fc1665872a2f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1616c5bc169a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnum_of_training_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mnum_of_testing_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/cityscapes-image-pairs/cityscapes_data/cityscapes_data/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vCKnpIko5DEg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}